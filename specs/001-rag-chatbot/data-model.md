# Data Model: RAG Chatbot Integration

**Feature**: RAG Chatbot Integration
**Branch**: `001-rag-chatbot`
**Date**: 2025-12-17
**Purpose**: Define all data entities, their relationships, validation rules, and storage schema

## Overview

This document defines the data model for the RAG chatbot system, including entities stored in Qdrant (vector embeddings), Neon Postgres (metadata and logs), and in-memory structures (API request/response models).

---

## Entity Catalog

| Entity | Storage | Purpose | Key Fields |
|--------|---------|---------|------------|
| DocumentChunk | Qdrant | Book content segments with embeddings | id, text, embedding, metadata |
| QueryRequest | In-memory (API) | User query input | query, mode, selected_text, session_id |
| QueryResponse | In-memory (API) | Generated answer output | answer, sources, response_time_ms |
| QueryLog | Neon Postgres | Query/answer audit trail | id, query_text, answer_text, source_chunks |
| IngestionLog | Neon Postgres | Ingestion process tracking | id, status, total_chunks, timestamps |
| ConversationTurn | In-memory (client) | Chat message history | role, content, timestamp |

---

## Entity Definitions

### 1. DocumentChunk

**Purpose**: Represents a segment of book content with its vector embedding and metadata for retrieval

**Storage**: Qdrant Cloud (vector database)

**Fields**:

| Field | Type | Required | Description | Validation |
|-------|------|----------|-------------|------------|
| id | UUID | Yes | Unique chunk identifier | Auto-generated by Qdrant |
| text | String | Yes | Chunk content (raw text) | 100-2000 characters |
| embedding | Float32[] | Yes | Vector representation (1536 dimensions) | Normalized vector |
| chapter | String | Yes | Chapter title or number | Max 200 chars |
| section | String | No | Section/subsection title | Max 200 chars |
| source_file | String | Yes | Markdown filename | Must match `*.md` pattern |
| heading_path | String[] | No | Heading hierarchy [H1, H2, H3] | Max 5 levels |
| page_number | Integer | No | Estimated page number | 1-1000 |
| chunk_index | Integer | Yes | Position in document | 0-indexed |
| created_at | Timestamp | Yes | Ingestion timestamp | ISO 8601 format |

**Qdrant Schema**:
```python
{
    "id": "uuid-string",
    "vector": [0.012, -0.034, ...],  # 1536 floats
    "payload": {
        "text": "Chunk content here...",
        "chapter": "Chapter 1: Introduction",
        "section": "Getting Started with Spec-Kit Plus",
        "source_file": "chapter-1-spec-kit.md",
        "heading_path": ["Chapter 1", "Getting Started", "Installation"],
        "page_number": 15,
        "chunk_index": 3,
        "created_at": "2025-12-17T10:30:00Z"
    }
}
```

**Relationships**:
- Many chunks → One source file
- Many chunks → One chapter
- Chunks are independent (no parent/child relationships)

**Validation Rules**:
- `text` must be non-empty and < 2000 characters
- `embedding` must be exactly 1536 dimensions (OpenAI text-embedding-3-small)
- `chapter` is required (extract from heading hierarchy)
- `source_file` must exist in `docs/` directory
- `chunk_index` must be unique per source_file

**Indexing**:
- Primary: Vector index (HNSW) on `embedding` field
- Secondary: Metadata filters on `chapter`, `section`, `source_file`

---

### 2. QueryRequest (API Input Model)

**Purpose**: Represents user query input to the chatbot API

**Storage**: In-memory (Pydantic model, not persisted)

**Fields**:

| Field | Type | Required | Description | Validation |
|-------|------|----------|-------------|------------|
| query | String | Yes | User's question | 3-500 words, non-empty |
| query_mode | Enum | No | "full_book" or "selected_text" | Default: "full_book" |
| selected_text | String | Conditional | Text user selected (required if mode=selected_text) | 20-5000 characters |
| conversation_history | ConversationTurn[] | No | Previous turns for context | Max 10 turns |
| session_id | UUID | No | Session identifier | UUID v4 format |
| top_k | Integer | No | Number of chunks to retrieve | 3-10, default 5 |

**Pydantic Model**:
```python
from pydantic import BaseModel, Field, validator
from typing import Optional, List
from enum import Enum
from uuid import UUID

class QueryMode(str, Enum):
    FULL_BOOK = "full_book"
    SELECTED_TEXT = "selected_text"

class ConversationTurn(BaseModel):
    role: str = Field(..., regex="^(user|assistant)$")
    content: str = Field(..., min_length=1, max_length=2000)

class QueryRequest(BaseModel):
    query: str = Field(..., min_length=10, max_length=2000)
    query_mode: QueryMode = QueryMode.FULL_BOOK
    selected_text: Optional[str] = Field(None, min_length=20, max_length=5000)
    conversation_history: List[ConversationTurn] = Field(default_factory=list, max_items=10)
    session_id: Optional[UUID] = None
    top_k: int = Field(5, ge=3, le=10)

    @validator('selected_text')
    def validate_selected_text(cls, v, values):
        if values.get('query_mode') == QueryMode.SELECTED_TEXT and not v:
            raise ValueError('selected_text is required when query_mode is selected_text')
        return v
```

**Validation Rules**:
- `query` must be 10-2000 characters (3-500 words approx)
- `selected_text` required if `query_mode` is "selected_text"
- `conversation_history` max 10 turns to prevent context overflow
- `top_k` must be 3-10 (balance between quality and cost)

---

### 3. QueryResponse (API Output Model)

**Purpose**: Represents chatbot's generated answer and metadata

**Storage**: In-memory (Pydantic model, not persisted but logged to Neon)

**Fields**:

| Field | Type | Required | Description | Validation |
|-------|------|----------|-------------|------------|
| answer | String | Yes | Generated answer text | 20-2000 characters |
| sources | SourceCitation[] | No | Source chunks referenced | Empty if no sources found |
| mode | Enum | Yes | "full_book" or "selected_text" | Mirrors request mode |
| session_id | UUID | Yes | Session identifier | UUID v4 format |
| response_time_ms | Integer | Yes | Processing time | 0-10000ms |
| confidence_score | Float | No | Answer confidence (future) | 0.0-1.0 |

**SourceCitation Sub-Model**:

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| chapter | String | Yes | Chapter title |
| section | String | No | Section title |
| file | String | Yes | Source markdown file |
| url | String | Yes | Deep link to book section |
| similarity_score | Float | Yes | Cosine similarity (0-1) |
| excerpt | String | No | Text snippet from chunk |

**Pydantic Model**:
```python
class SourceCitation(BaseModel):
    chapter: str = Field(..., max_length=200)
    section: Optional[str] = Field(None, max_length=200)
    file: str = Field(..., regex=r".*\.md$")
    url: str = Field(..., regex=r"^/docs/.*")
    similarity_score: float = Field(..., ge=0.0, le=1.0)
    excerpt: Optional[str] = Field(None, max_length=500)

class QueryResponse(BaseModel):
    answer: str = Field(..., min_length=20, max_length=2000)
    sources: List[SourceCitation] = Field(default_factory=list)
    mode: QueryMode
    session_id: UUID
    response_time_ms: int = Field(..., ge=0, le=10000)
    confidence_score: Optional[float] = Field(None, ge=0.0, le=1.0)
```

**Validation Rules**:
- `answer` must be 20-2000 characters (non-empty, not too long)
- `sources` can be empty (e.g., no relevant chunks found)
- `response_time_ms` must be < 10s (timeout threshold)
- `url` must be valid relative path (e.g., `/docs/chapter-1#section`)

---

### 4. QueryLog (Neon Postgres)

**Purpose**: Persistent audit trail of all queries and answers for monitoring and analysis

**Storage**: Neon Serverless Postgres (table: `query_logs`)

**Fields**:

| Field | Type | Required | Description | Constraints |
|-------|------|----------|-------------|-------------|
| id | UUID | Yes | Primary key | Auto-generated |
| session_id | UUID | Yes | Groups queries in conversation | Indexed |
| query_text | TEXT | Yes | User's question | - |
| query_mode | VARCHAR(20) | Yes | "full_book" or "selected_text" | CHECK constraint |
| selected_text | TEXT | No | User-selected text (if applicable) | Nullable |
| answer_text | TEXT | Yes | Generated answer | - |
| source_chunks | JSONB | Yes | Array of source citations | Valid JSON array |
| response_time_ms | INTEGER | Yes | Processing duration | >= 0 |
| created_at | TIMESTAMP | Yes | Query timestamp | Default NOW() |

**SQL Schema**:
```sql
CREATE TABLE query_logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID NOT NULL,
    query_text TEXT NOT NULL,
    query_mode VARCHAR(20) NOT NULL CHECK (query_mode IN ('full_book', 'selected_text')),
    selected_text TEXT,
    answer_text TEXT NOT NULL,
    source_chunks JSONB NOT NULL DEFAULT '[]'::jsonb,
    response_time_ms INTEGER NOT NULL CHECK (response_time_ms >= 0),
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_query_logs_session ON query_logs(session_id);
CREATE INDEX idx_query_logs_created ON query_logs(created_at DESC);
CREATE INDEX idx_query_logs_mode ON query_logs(query_mode);
```

**JSONB Structure for `source_chunks`**:
```json
[
    {
        "chapter": "Chapter 1",
        "section": "Introduction",
        "file": "chapter-1-spec-kit.md",
        "url": "/docs/chapter-1-spec-kit#introduction",
        "similarity_score": 0.92
    },
    {
        "chapter": "Chapter 3",
        "section": "Claude Code Setup",
        "file": "chapter-3-claude-code.md",
        "url": "/docs/chapter-3-claude-code#setup",
        "similarity_score": 0.87
    }
]
```

**Relationships**:
- Many QueryLog → One session_id (conversation grouping)

**Validation Rules**:
- `query_text` and `answer_text` cannot be empty
- `query_mode` must be one of the enum values
- `source_chunks` must be valid JSON array
- `response_time_ms` must be non-negative

**Retention Policy** (future):
- Keep logs for 90 days
- Archive older logs to S3/cold storage
- Implement GDPR-compliant deletion

---

### 5. IngestionLog (Neon Postgres)

**Purpose**: Track ingestion pipeline runs for debugging and monitoring

**Storage**: Neon Serverless Postgres (table: `ingestion_logs`)

**Fields**:

| Field | Type | Required | Description | Constraints |
|-------|------|----------|-------------|-------------|
| id | UUID | Yes | Primary key | Auto-generated |
| started_at | TIMESTAMP | Yes | Ingestion start time | Default NOW() |
| completed_at | TIMESTAMP | No | Ingestion end time | Must be > started_at |
| status | VARCHAR(20) | Yes | "running", "completed", "failed" | CHECK constraint |
| total_chunks | INTEGER | No | Number of chunks created | >= 0 |
| total_files | INTEGER | No | Number of markdown files processed | >= 0 |
| error_message | TEXT | No | Error details if failed | Nullable |
| metadata | JSONB | No | Additional ingestion params | Nullable |

**SQL Schema**:
```sql
CREATE TABLE ingestion_logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    started_at TIMESTAMP DEFAULT NOW(),
    completed_at TIMESTAMP,
    status VARCHAR(20) NOT NULL CHECK (status IN ('running', 'completed', 'failed')),
    total_chunks INTEGER CHECK (total_chunks >= 0),
    total_files INTEGER CHECK (total_files >= 0),
    error_message TEXT,
    metadata JSONB,
    CONSTRAINT check_completed_after_started CHECK (completed_at IS NULL OR completed_at >= started_at)
);

CREATE INDEX idx_ingestion_logs_status ON ingestion_logs(status);
CREATE INDEX idx_ingestion_logs_started ON ingestion_logs(started_at DESC);
```

**JSONB Structure for `metadata`**:
```json
{
    "chunk_size": 800,
    "chunk_overlap": 100,
    "embedding_model": "text-embedding-3-small",
    "source_directory": "ai-powered-book/docs/",
    "qdrant_collection": "book_chunks"
}
```

**State Transitions**:
```
running → completed (success)
running → failed (error)
```

**Validation Rules**:
- `status` must be one of the enum values
- `completed_at` must be after `started_at`
- `error_message` required if `status` is "failed"
- `total_chunks` and `total_files` must be non-negative

---

### 6. ConversationTurn (In-Memory)

**Purpose**: Represents a single message in the conversation history (client-side state)

**Storage**: In-memory (client-side, passed in API requests)

**Fields**:

| Field | Type | Required | Description | Validation |
|-------|------|----------|-------------|------------|
| role | Enum | Yes | "user" or "assistant" | One of two values |
| content | String | Yes | Message text | 1-2000 characters |
| timestamp | Timestamp | No | Message creation time | ISO 8601 format |

**TypeScript Interface** (Frontend):
```typescript
interface ConversationTurn {
    role: 'user' | 'assistant';
    content: string;
    timestamp?: string; // ISO 8601
}
```

**Validation Rules**:
- `role` must be "user" or "assistant"
- `content` must be non-empty and < 2000 characters
- `timestamp` is optional (for display purposes)

**Usage**:
- Maintained client-side (React state)
- Passed in API requests for conversation context
- Not persisted server-side (stateless API)

---

## Data Flow Diagrams

### Ingestion Flow

```
Markdown Files (docs/)
    ↓
Parse & Extract Metadata
(chapter, section, headings)
    ↓
Chunk with Overlap
(800 tokens, 100 overlap)
    ↓
Generate Embeddings
(OpenAI text-embedding-3-small)
    ↓
Store in Qdrant
(DocumentChunk entity)
    ↓
Log Ingestion Status
(IngestionLog in Neon)
```

### Query Flow (Full-Book Mode)

```
User Query (QueryRequest)
    ↓
Generate Query Embedding
(OpenAI API)
    ↓
Search Qdrant
(Top-k DocumentChunks by similarity)
    ↓
Compose Prompt
(System prompt + Context + Query)
    ↓
Generate Answer
(OpenAI Chat Completions)
    ↓
Extract Sources
(From chunk metadata)
    ↓
Return Response (QueryResponse)
    ↓
Log to Neon (QueryLog)
```

### Query Flow (Selected-Text Mode)

```
User Query + Selected Text (QueryRequest)
    ↓
Skip Embedding & Vector Search
    ↓
Compose Prompt
(System prompt + Selected Text + Query)
    ↓
Generate Answer
(OpenAI Chat Completions)
    ↓
Return Response (QueryResponse)
(No sources, disclaimer included)
    ↓
Log to Neon (QueryLog)
```

---

## Validation & Constraints Summary

### Input Validation (API Layer)

| Field | Min Length | Max Length | Pattern | Default |
|-------|-----------|-----------|---------|---------|
| query | 10 chars | 2000 chars | - | - |
| selected_text | 20 chars | 5000 chars | - | - |
| top_k | 3 | 10 | Integer | 5 |
| conversation_history | 0 turns | 10 turns | - | [] |

### Storage Constraints (Qdrant)

| Field | Constraint | Reason |
|-------|-----------|--------|
| embedding | Exactly 1536 dimensions | OpenAI text-embedding-3-small |
| text | 100-2000 chars | Chunk size limits |
| chapter | Required | Needed for source attribution |

### Storage Constraints (Neon)

| Table | Size Estimate | Retention |
|-------|--------------|-----------|
| query_logs | ~1KB per row | 90 days |
| ingestion_logs | ~500B per row | Indefinite |
| **Total** | ~10-50MB for 10k queries | - |

---

## Scalability Considerations

### Current Scale (v1)
- **Book size**: 500 pages max
- **Chunks**: ~1000 (within Qdrant free tier)
- **Queries**: ~10k/month (within OpenAI/Neon limits)
- **Concurrent users**: 100 (stateless API, no sessions)

### Future Scale (v2+)
- **Multiple books**: Separate Qdrant collections per book
- **Larger books**: Increase chunk size (800 → 1200 tokens)
- **More queries**: Upgrade to paid tiers (Qdrant, Neon, OpenAI)
- **Conversation history**: Store in Neon instead of client-side

---

## Data Security & Privacy

### PII Handling
- **No PII collected**: Queries are anonymous (no user authentication)
- **Session IDs**: UUIDs, no user identifiers
- **IP addresses**: Used only for rate limiting, not logged

### Data Retention
- **Query logs**: 90 days (for quality monitoring)
- **Embeddings**: Indefinite (static book content)
- **Ingestion logs**: Indefinite (debugging purposes)

### GDPR Compliance
- No personal data collected (no user accounts)
- Query logs are pseudonymous (session IDs only)
- Right to deletion: Not applicable (no user accounts)

---

## Error Handling

### Invalid Input Errors (400)
- Empty query
- Query too long (> 2000 chars)
- Selected text missing (when mode=selected_text)
- Invalid session_id format

### Not Found Errors (404)
- No relevant chunks found (return "no information found" response)

### Rate Limit Errors (429)
- > 100 requests/hour per IP

### Service Errors (503)
- Qdrant unavailable
- Neon unavailable
- OpenAI API unavailable

---

## References

- **Qdrant Schema**: [Qdrant Documentation](https://qdrant.tech/documentation/concepts/collections/)
- **Pydantic Models**: [Pydantic Documentation](https://docs.pydantic.dev/)
- **PostgreSQL JSONB**: [PostgreSQL JSONB Documentation](https://www.postgresql.org/docs/current/datatype-json.html)

---

**Last Updated**: 2025-12-17
**Status**: Complete - Ready for API contract generation
